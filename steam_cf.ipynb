{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/tamber/steam-video-games?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "df = pd.read_csv(\"data/steam-200k.csv\")\n",
    "df.columns = ['user_id', 'title', 'action', 'hours', 'x']\n",
    "\n",
    "# del last col\n",
    "df = df.drop('x', axis=1)\n",
    "\n",
    "# remove all purchase actions\n",
    "df = df.drop(df[df['action'] == 'purchase'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>action</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151603712</td>\n",
       "      <td>The Elder Scrolls V Skyrim</td>\n",
       "      <td>play</td>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151603712</td>\n",
       "      <td>Fallout 4</td>\n",
       "      <td>play</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151603712</td>\n",
       "      <td>Spore</td>\n",
       "      <td>play</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>151603712</td>\n",
       "      <td>Fallout New Vegas</td>\n",
       "      <td>play</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>151603712</td>\n",
       "      <td>Left 4 Dead 2</td>\n",
       "      <td>play</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199990</th>\n",
       "      <td>128470551</td>\n",
       "      <td>Fallen Earth</td>\n",
       "      <td>play</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199992</th>\n",
       "      <td>128470551</td>\n",
       "      <td>Magic Duels</td>\n",
       "      <td>play</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199994</th>\n",
       "      <td>128470551</td>\n",
       "      <td>Titan Souls</td>\n",
       "      <td>play</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>128470551</td>\n",
       "      <td>Grand Theft Auto Vice City</td>\n",
       "      <td>play</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>128470551</td>\n",
       "      <td>RUSH</td>\n",
       "      <td>play</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70489 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id                       title action  hours\n",
       "0       151603712  The Elder Scrolls V Skyrim   play  273.0\n",
       "2       151603712                   Fallout 4   play   87.0\n",
       "4       151603712                       Spore   play   14.9\n",
       "6       151603712           Fallout New Vegas   play   12.1\n",
       "8       151603712               Left 4 Dead 2   play    8.9\n",
       "...           ...                         ...    ...    ...\n",
       "199990  128470551                Fallen Earth   play    2.4\n",
       "199992  128470551                 Magic Duels   play    2.2\n",
       "199994  128470551                 Titan Souls   play    1.5\n",
       "199996  128470551  Grand Theft Auto Vice City   play    1.5\n",
       "199998  128470551                        RUSH   play    1.4\n",
       "\n",
       "[70489 rows x 4 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hours\n",
       "0.2       3016\n",
       "0.3       2517\n",
       "0.4       2129\n",
       "0.5       1813\n",
       "0.1       1787\n",
       "          ... \n",
       "724.0        1\n",
       "737.0        1\n",
       "3503.0       1\n",
       "1397.0       1\n",
       "1310.0       1\n",
       "Name: count, Length: 1593, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.hours.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users is: 11350\n",
      "Number of unique games is: 3600\n",
      "Number of ratings 70489\n",
      "Matrix size: 40860000\n",
      "Percent of matrix that is filled: 0.17251346059716105 %\n"
     ]
    }
   ],
   "source": [
    "n_users = df['user_id'].nunique()\n",
    "n_items = df['title'].nunique()\n",
    "\n",
    "\n",
    "print(\"Number of unique users is:\", n_users)\n",
    "print(\"Number of unique games is:\", n_items)\n",
    "print(\"Number of ratings\", len(df))\n",
    "print(\"Matrix size:\", n_users*n_items)\n",
    "print(\"Percent of matrix that is filled:\", len(df) / (n_users*n_items) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "#import mathplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, model_selection\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class GameDataset(Dataset):\n",
    "    def __init__(self, users, items, hours):\n",
    "        self.users = users\n",
    "        self.items = items\n",
    "        self.hours = hours\n",
    "        \n",
    "    # len(movie_dataset)\n",
    "    def __len__(self): # Number of Users\n",
    "        return len(self.users)\n",
    "\n",
    "    # movie_dataset[1]\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        users = self.users[idx]\n",
    "        items = self.items[idx]\n",
    "        hours = self.hours[idx]\n",
    "\n",
    "        return {\n",
    "            \"user_id\" : torch.tensor(users, dtype=torch.long),\n",
    "            \"title\" : torch.tensor(items, dtype=torch.long),\n",
    "            \"hours\" : torch.tensor(hours, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSysModel(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_size=256, hidden_dim=256, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        #create embeddings\n",
    "        self.user_embed = torch.nn.Embedding(num_embeddings=n_users, embedding_dim=embedding_size)\n",
    "        self.item_embed = torch.nn.Embedding(num_embeddings=n_items, embedding_dim=embedding_size)\n",
    "\n",
    "\n",
    "        # hidden layers\n",
    "        self.fc1 = torch.nn.Linear(2 * embedding_size, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(p=dropout_rate)\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, users, items, hours=None):\n",
    "        user_embeds = self.user_embed(users)\n",
    "        item_embeds = self.item_embed(items)\n",
    "        \n",
    "        output = torch.cat([user_embeds, item_embeds], dim=1)\n",
    "\n",
    "        x = self.relu(self.fc1(output))\n",
    "        x = self.dropout(x)\n",
    "        output = self.fc2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_user = preprocessing.LabelEncoder()\n",
    "lbl_item = preprocessing.LabelEncoder()\n",
    "df['user_id'] = lbl_user.fit_transform(df['user_id'].values)\n",
    "df['title'] = lbl_item.fit_transform(df['title'].values)\n",
    "\n",
    "df_train, df_valid = model_selection.train_test_split(\n",
    "    df, test_size=0.1, random_state=3\n",
    ")\n",
    "\n",
    "train_dataset = GameDataset(\n",
    "    users = df_train['user_id'].values,\n",
    "    items = df_train['title'].values,\n",
    "    hours = df_train['hours'].values,\n",
    "    \n",
    ")\n",
    "\n",
    "valid_dataset = GameDataset(\n",
    "    users = df_valid['user_id'].values,\n",
    "    items = df_valid['title'].values,\n",
    "    hours = df_valid['hours'].values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recommendation_model = RecSysModel(n_users, n_items, embedding_size=64, hidden_dim=128, dropout_rate=0.1).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(recommendation_model.parameters()) #gradient descent aka adjust to yield smallest error\n",
    "sch = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.7)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on size: 63440\n",
      "epoch 0 loss at step 800 is 7290.598701171875\n",
      "epoch 0 loss at step 1600 is 5022.93665222168\n",
      "epoch 0 loss at step 2400 is 11360.008327789306\n",
      "epoch 0 loss at step 3200 is 11255.827570037842\n",
      "epoch 0 loss at step 4000 is 27058.720556945802\n",
      "epoch 0 loss at step 4800 is 12488.279372558594\n",
      "epoch 0 loss at step 5600 is 13190.327606277466\n",
      "epoch 0 loss at step 6400 is 4659.6195458984375\n",
      "epoch 0 loss at step 7200 is 10582.276041259765\n",
      "epoch 0 loss at step 8000 is 12286.337452392578\n",
      "epoch 0 loss at step 8800 is 12890.308620605469\n",
      "epoch 0 loss at step 9600 is 21748.31109466553\n",
      "epoch 0 loss at step 10400 is 10554.670635375976\n",
      "epoch 0 loss at step 11200 is 7806.033176269531\n",
      "epoch 0 loss at step 12000 is 16737.047279052735\n",
      "epoch 0 loss at step 12800 is 8705.542124023437\n",
      "epoch 0 loss at step 13600 is 28647.48538696289\n",
      "epoch 0 loss at step 14400 is 9877.084731445313\n",
      "epoch 0 loss at step 15200 is 24846.773060302734\n",
      "epoch 0 loss at step 16000 is 16537.170620117187\n",
      "epoch 0 loss at step 16800 is 5410.557641601563\n",
      "epoch 0 loss at step 17600 is 3094.911994628906\n",
      "epoch 0 loss at step 18400 is 15569.17375\n",
      "epoch 0 loss at step 19200 is 24372.953725585936\n",
      "epoch 0 loss at step 20000 is 13709.57576171875\n",
      "epoch 0 loss at step 20800 is 13370.856740722656\n",
      "epoch 0 loss at step 21600 is 8801.190866699219\n",
      "epoch 0 loss at step 22400 is 10953.655871582032\n",
      "epoch 0 loss at step 23200 is 4323.89219909668\n",
      "epoch 0 loss at step 24000 is 11995.258673095703\n",
      "epoch 0 loss at step 24800 is 49424.49457275391\n",
      "epoch 0 loss at step 25600 is 5434.656083374023\n",
      "epoch 0 loss at step 26400 is 5515.590673828125\n",
      "epoch 0 loss at step 27200 is 16028.389143066406\n",
      "epoch 0 loss at step 28000 is 7144.530090332031\n",
      "epoch 0 loss at step 28800 is 3465.0213879394532\n",
      "epoch 0 loss at step 29600 is 7081.64791015625\n",
      "epoch 0 loss at step 30400 is 8048.507265625\n",
      "epoch 0 loss at step 31200 is 17701.559802856445\n",
      "epoch 0 loss at step 32000 is 11002.121875915527\n",
      "epoch 0 loss at step 32800 is 15528.969499511719\n",
      "epoch 0 loss at step 33600 is 9581.844860839843\n",
      "epoch 0 loss at step 34400 is 16068.133171386718\n",
      "epoch 0 loss at step 35200 is 20593.625582275392\n",
      "epoch 0 loss at step 36000 is 2790.6671337890625\n",
      "epoch 0 loss at step 36800 is 6488.94206237793\n",
      "epoch 0 loss at step 37600 is 21387.965783691405\n",
      "epoch 0 loss at step 38400 is 46378.33676269531\n",
      "epoch 0 loss at step 39200 is 13975.0198828125\n",
      "epoch 0 loss at step 40000 is 3890.1211547851562\n",
      "epoch 0 loss at step 40800 is 5982.056625976563\n",
      "epoch 0 loss at step 41600 is 4831.002758789063\n",
      "epoch 0 loss at step 42400 is 40914.321635742184\n",
      "epoch 0 loss at step 43200 is 7409.840385742187\n",
      "epoch 0 loss at step 44000 is 10917.844261474609\n",
      "epoch 0 loss at step 44800 is 14596.574799804688\n",
      "epoch 0 loss at step 45600 is 22189.64973388672\n",
      "epoch 0 loss at step 46400 is 10832.895319824218\n",
      "epoch 0 loss at step 47200 is 6670.1504736328125\n",
      "epoch 0 loss at step 48000 is 6148.676606445312\n",
      "epoch 0 loss at step 48800 is 12803.792760009766\n",
      "epoch 0 loss at step 49600 is 14294.634041748046\n",
      "epoch 0 loss at step 50400 is 6025.312230224609\n",
      "epoch 0 loss at step 51200 is 5906.480771484375\n",
      "epoch 0 loss at step 52000 is 22900.392145996095\n",
      "epoch 0 loss at step 52800 is 5548.975356445312\n",
      "epoch 0 loss at step 53600 is 4287.371844482422\n",
      "epoch 0 loss at step 54400 is 9774.096206054688\n",
      "epoch 0 loss at step 55200 is 13063.772287597656\n",
      "epoch 0 loss at step 56000 is 8409.024624023437\n",
      "epoch 0 loss at step 56800 is 7614.408386230469\n",
      "epoch 0 loss at step 57600 is 10528.493833007813\n",
      "epoch 0 loss at step 58400 is 15278.600412597656\n",
      "epoch 0 loss at step 59200 is 10223.539970703125\n",
      "epoch 0 loss at step 60000 is 6504.005628662109\n",
      "epoch 0 loss at step 60800 is 9699.575751953125\n",
      "epoch 0 loss at step 61600 is 6039.445048828125\n",
      "epoch 0 loss at step 62400 is 19255.795244140623\n",
      "epoch 0 loss at step 63200 is 16779.03549560547\n",
      "epoch 0 loss at step 63440 is 2417.0783508300783\n",
      "epoch 1 loss at step 800 is 5146.59337890625\n",
      "epoch 1 loss at step 1600 is 16231.880229492188\n",
      "epoch 1 loss at step 2400 is 7664.491076049805\n",
      "epoch 1 loss at step 3200 is 14216.61818359375\n",
      "epoch 1 loss at step 4000 is 10360.489204101563\n",
      "epoch 1 loss at step 4800 is 4778.991381835937\n",
      "epoch 1 loss at step 5600 is 50791.95366210937\n",
      "epoch 1 loss at step 6400 is 3165.519343261719\n",
      "epoch 1 loss at step 7200 is 8504.582895507812\n",
      "epoch 1 loss at step 8000 is 6933.507524414063\n",
      "epoch 1 loss at step 8800 is 10702.013369140624\n",
      "epoch 1 loss at step 9600 is 9264.371279296874\n",
      "epoch 1 loss at step 10400 is 23050.991437988283\n",
      "epoch 1 loss at step 11200 is 12492.34986328125\n",
      "epoch 1 loss at step 12000 is 19178.651125488283\n",
      "epoch 1 loss at step 12800 is 8546.724969482422\n",
      "epoch 1 loss at step 13600 is 5977.661456298828\n",
      "epoch 1 loss at step 14400 is 10511.127890625\n",
      "epoch 1 loss at step 15200 is 5826.336826171875\n",
      "epoch 1 loss at step 16000 is 4222.568369140625\n",
      "epoch 1 loss at step 16800 is 3511.6825817871095\n",
      "epoch 1 loss at step 17600 is 6554.929890136718\n",
      "epoch 1 loss at step 18400 is 7330.149111328125\n",
      "epoch 1 loss at step 19200 is 14205.66453125\n",
      "epoch 1 loss at step 20000 is 8896.970635986328\n",
      "epoch 1 loss at step 20800 is 5100.05232421875\n",
      "epoch 1 loss at step 21600 is 10130.860705566407\n",
      "epoch 1 loss at step 22400 is 9175.344272460938\n",
      "epoch 1 loss at step 23200 is 11783.105546875\n",
      "epoch 1 loss at step 24000 is 13587.57608642578\n",
      "epoch 1 loss at step 24800 is 22559.87174560547\n",
      "epoch 1 loss at step 25600 is 6157.500541992187\n",
      "epoch 1 loss at step 26400 is 15670.05203125\n",
      "epoch 1 loss at step 27200 is 4766.322532348633\n",
      "epoch 1 loss at step 28000 is 9764.389194335938\n",
      "epoch 1 loss at step 28800 is 4586.121755371094\n",
      "epoch 1 loss at step 29600 is 9421.398032226563\n",
      "epoch 1 loss at step 30400 is 23841.118447265624\n",
      "epoch 1 loss at step 31200 is 16573.221081542968\n",
      "epoch 1 loss at step 32000 is 7837.242075195312\n",
      "epoch 1 loss at step 32800 is 43882.26870605469\n",
      "epoch 1 loss at step 33600 is 10699.513076171876\n",
      "epoch 1 loss at step 34400 is 11263.2998046875\n",
      "epoch 1 loss at step 35200 is 10929.599725341797\n",
      "epoch 1 loss at step 36000 is 16126.798936767578\n",
      "epoch 1 loss at step 36800 is 12602.877305908203\n",
      "epoch 1 loss at step 37600 is 5022.018823242188\n",
      "epoch 1 loss at step 38400 is 3725.54337890625\n",
      "epoch 1 loss at step 39200 is 9507.180076293946\n",
      "epoch 1 loss at step 40000 is 3980.6864721679685\n",
      "epoch 1 loss at step 40800 is 6960.685529785156\n",
      "epoch 1 loss at step 41600 is 4997.98650390625\n",
      "epoch 1 loss at step 42400 is 9687.056768798828\n",
      "epoch 1 loss at step 43200 is 10897.498024902343\n",
      "epoch 1 loss at step 44000 is 21132.630283203125\n",
      "epoch 1 loss at step 44800 is 12143.648696289063\n",
      "epoch 1 loss at step 45600 is 9607.655396728516\n",
      "epoch 1 loss at step 46400 is 20236.8443359375\n",
      "epoch 1 loss at step 47200 is 13802.579543457032\n",
      "epoch 1 loss at step 48000 is 10632.946328125\n",
      "epoch 1 loss at step 48800 is 10164.18427734375\n",
      "epoch 1 loss at step 49600 is 6693.135548095703\n",
      "epoch 1 loss at step 50400 is 37322.63122070312\n",
      "epoch 1 loss at step 51200 is 5067.6968920898435\n",
      "epoch 1 loss at step 52000 is 6984.652309570312\n",
      "epoch 1 loss at step 52800 is 24553.46905029297\n",
      "epoch 1 loss at step 53600 is 18252.346220703126\n",
      "epoch 1 loss at step 54400 is 10121.121296386718\n",
      "epoch 1 loss at step 55200 is 18946.46844482422\n",
      "epoch 1 loss at step 56000 is 4453.815417480469\n",
      "epoch 1 loss at step 56800 is 10319.646044921876\n",
      "epoch 1 loss at step 57600 is 41320.4116015625\n",
      "epoch 1 loss at step 58400 is 14767.80624206543\n",
      "epoch 1 loss at step 59200 is 8625.928834228516\n",
      "epoch 1 loss at step 60000 is 5765.875412597657\n",
      "epoch 1 loss at step 60800 is 6727.386440429687\n",
      "epoch 1 loss at step 61600 is 26326.71633300781\n",
      "epoch 1 loss at step 62400 is 3807.3861584472656\n",
      "epoch 1 loss at step 63200 is 20561.102978515624\n",
      "epoch 1 loss at step 63440 is 811.1087084960938\n",
      "epoch 2 loss at step 800 is 12329.571142578125\n",
      "epoch 2 loss at step 1600 is 39386.90895385742\n",
      "epoch 2 loss at step 2400 is 5436.172087402344\n",
      "epoch 2 loss at step 3200 is 2389.8148681640623\n",
      "epoch 2 loss at step 4000 is 12233.80572631836\n",
      "epoch 2 loss at step 4800 is 7257.0186328125\n",
      "epoch 2 loss at step 5600 is 7053.188430175781\n",
      "epoch 2 loss at step 6400 is 16538.046481933594\n",
      "epoch 2 loss at step 7200 is 7796.336759033203\n",
      "epoch 2 loss at step 8000 is 14476.927670898438\n",
      "epoch 2 loss at step 8800 is 9632.39046875\n",
      "epoch 2 loss at step 9600 is 6809.535153808593\n",
      "epoch 2 loss at step 10400 is 11423.432119140625\n",
      "epoch 2 loss at step 11200 is 20955.48177001953\n",
      "epoch 2 loss at step 12000 is 18549.383209228516\n",
      "epoch 2 loss at step 12800 is 10526.013349609375\n",
      "epoch 2 loss at step 13600 is 5241.2032397460935\n",
      "epoch 2 loss at step 14400 is 16468.531525878905\n",
      "epoch 2 loss at step 15200 is 4225.423522949219\n",
      "epoch 2 loss at step 16000 is 6404.9113488769535\n",
      "epoch 2 loss at step 16800 is 3559.2415380859375\n",
      "epoch 2 loss at step 17600 is 5997.956330566406\n",
      "epoch 2 loss at step 18400 is 10389.004620361327\n",
      "epoch 2 loss at step 19200 is 3955.6475610351563\n",
      "epoch 2 loss at step 20000 is 10102.34041748047\n",
      "epoch 2 loss at step 20800 is 3245.401326904297\n",
      "epoch 2 loss at step 21600 is 18616.65401123047\n",
      "epoch 2 loss at step 22400 is 10332.233319091796\n",
      "epoch 2 loss at step 23200 is 8688.914252929688\n",
      "epoch 2 loss at step 24000 is 5671.609162597656\n",
      "epoch 2 loss at step 24800 is 10488.690166015625\n",
      "epoch 2 loss at step 25600 is 6264.161677246094\n",
      "epoch 2 loss at step 26400 is 9310.583115234374\n",
      "epoch 2 loss at step 27200 is 7739.4250390625\n",
      "epoch 2 loss at step 28000 is 6234.52140625\n",
      "epoch 2 loss at step 28800 is 10755.244537353516\n",
      "epoch 2 loss at step 29600 is 9635.18955078125\n",
      "epoch 2 loss at step 30400 is 6503.4613977050785\n",
      "epoch 2 loss at step 31200 is 33101.87640869141\n",
      "epoch 2 loss at step 32000 is 6216.303188476562\n",
      "epoch 2 loss at step 32800 is 7483.743305664062\n",
      "epoch 2 loss at step 33600 is 63750.756184082034\n",
      "epoch 2 loss at step 34400 is 11459.221813964843\n",
      "epoch 2 loss at step 35200 is 9820.107309570312\n",
      "epoch 2 loss at step 36000 is 7844.979572753906\n",
      "epoch 2 loss at step 36800 is 7348.831171875\n",
      "epoch 2 loss at step 37600 is 10048.426010742187\n",
      "epoch 2 loss at step 38400 is 10375.529522705077\n",
      "epoch 2 loss at step 39200 is 12149.116900634766\n",
      "epoch 2 loss at step 40000 is 8942.01703125\n",
      "epoch 2 loss at step 40800 is 11600.332563476562\n",
      "epoch 2 loss at step 41600 is 10747.993454589843\n",
      "epoch 2 loss at step 42400 is 2750.4879040527344\n",
      "epoch 2 loss at step 43200 is 6448.905651245117\n",
      "epoch 2 loss at step 44000 is 6848.315361328125\n",
      "epoch 2 loss at step 44800 is 7926.269729003906\n",
      "epoch 2 loss at step 45600 is 18355.971540527345\n",
      "epoch 2 loss at step 46400 is 12377.710512084961\n",
      "epoch 2 loss at step 47200 is 21538.15321533203\n",
      "epoch 2 loss at step 48000 is 4019.1345977783203\n",
      "epoch 2 loss at step 48800 is 2882.589074707031\n",
      "epoch 2 loss at step 49600 is 5234.99153930664\n",
      "epoch 2 loss at step 50400 is 25893.3621875\n",
      "epoch 2 loss at step 51200 is 5829.236049804687\n",
      "epoch 2 loss at step 52000 is 36885.438952636716\n",
      "epoch 2 loss at step 52800 is 11874.80582763672\n",
      "epoch 2 loss at step 53600 is 9035.200300292969\n",
      "epoch 2 loss at step 54400 is 13523.099157714843\n",
      "epoch 2 loss at step 55200 is 17712.70037109375\n",
      "epoch 2 loss at step 56000 is 13660.64421875\n",
      "epoch 2 loss at step 56800 is 11900.381730957031\n",
      "epoch 2 loss at step 57600 is 31815.23141845703\n",
      "epoch 2 loss at step 58400 is 8801.248138427734\n",
      "epoch 2 loss at step 59200 is 12791.605174560547\n",
      "epoch 2 loss at step 60000 is 18798.353225097657\n",
      "epoch 2 loss at step 60800 is 17005.79667480469\n",
      "epoch 2 loss at step 61600 is 9841.126291503906\n",
      "epoch 2 loss at step 62400 is 13199.27501953125\n",
      "epoch 2 loss at step 63200 is 12477.36938232422\n",
      "epoch 2 loss at step 63440 is 1042.43033203125\n",
      "epoch 3 loss at step 800 is 10371.277509765625\n",
      "epoch 3 loss at step 1600 is 7331.476967163086\n",
      "epoch 3 loss at step 2400 is 7425.010034179688\n",
      "epoch 3 loss at step 3200 is 6465.1419677734375\n",
      "epoch 3 loss at step 4000 is 8914.326916503906\n",
      "epoch 3 loss at step 4800 is 6054.864162597656\n",
      "epoch 3 loss at step 5600 is 6713.245480957031\n",
      "epoch 3 loss at step 6400 is 8089.2302734375\n",
      "epoch 3 loss at step 7200 is 16121.77759765625\n",
      "epoch 3 loss at step 8000 is 6177.955053710937\n",
      "epoch 3 loss at step 8800 is 34912.14921569824\n",
      "epoch 3 loss at step 9600 is 2082.2199755859374\n",
      "epoch 3 loss at step 10400 is 11021.262068786622\n",
      "epoch 3 loss at step 11200 is 12158.201888427735\n",
      "epoch 3 loss at step 12000 is 17782.654067382813\n",
      "epoch 3 loss at step 12800 is 7848.590500488282\n",
      "epoch 3 loss at step 13600 is 13244.653455810547\n",
      "epoch 3 loss at step 14400 is 11849.114958496093\n",
      "epoch 3 loss at step 15200 is 9145.137333984376\n",
      "epoch 3 loss at step 16000 is 18589.83634765625\n",
      "epoch 3 loss at step 16800 is 11348.6882421875\n",
      "epoch 3 loss at step 17600 is 6760.425466308594\n",
      "epoch 3 loss at step 18400 is 9788.35392150879\n",
      "epoch 3 loss at step 19200 is 16927.708166503908\n",
      "epoch 3 loss at step 20000 is 9937.253864746093\n",
      "epoch 3 loss at step 20800 is 10456.632993164063\n",
      "epoch 3 loss at step 21600 is 5556.552763671875\n",
      "epoch 3 loss at step 22400 is 12098.72087158203\n",
      "epoch 3 loss at step 23200 is 14259.23671875\n",
      "epoch 3 loss at step 24000 is 14151.25587890625\n",
      "epoch 3 loss at step 24800 is 16707.308686523436\n",
      "epoch 3 loss at step 25600 is 14125.035695800781\n",
      "epoch 3 loss at step 26400 is 5031.667880859375\n",
      "epoch 3 loss at step 27200 is 22100.21698364258\n",
      "epoch 3 loss at step 28000 is 6955.170383300781\n",
      "epoch 3 loss at step 28800 is 10212.43908203125\n",
      "epoch 3 loss at step 29600 is 17417.935341796874\n",
      "epoch 3 loss at step 30400 is 5712.144185180664\n",
      "epoch 3 loss at step 31200 is 7205.364328613281\n",
      "epoch 3 loss at step 32000 is 2698.9610302734377\n",
      "epoch 3 loss at step 32800 is 10738.006130371094\n",
      "epoch 3 loss at step 33600 is 3007.849138183594\n",
      "epoch 3 loss at step 34400 is 10882.271225585937\n",
      "epoch 3 loss at step 35200 is 16771.049521484376\n",
      "epoch 3 loss at step 36000 is 5822.339235839844\n",
      "epoch 3 loss at step 36800 is 10300.364375\n",
      "epoch 3 loss at step 37600 is 5867.549619140625\n",
      "epoch 3 loss at step 38400 is 4947.457524414062\n",
      "epoch 3 loss at step 39200 is 6336.0313647460935\n",
      "epoch 3 loss at step 40000 is 20871.59396118164\n",
      "epoch 3 loss at step 40800 is 9548.026892089843\n",
      "epoch 3 loss at step 41600 is 7396.249755859375\n",
      "epoch 3 loss at step 42400 is 8385.396759033203\n",
      "epoch 3 loss at step 43200 is 15529.345589599609\n",
      "epoch 3 loss at step 44000 is 4934.24029296875\n",
      "epoch 3 loss at step 44800 is 3883.315129394531\n",
      "epoch 3 loss at step 45600 is 25252.751831054688\n",
      "epoch 3 loss at step 46400 is 3551.1849475097656\n",
      "epoch 3 loss at step 47200 is 18959.937407226564\n",
      "epoch 3 loss at step 48000 is 14620.428244628907\n",
      "epoch 3 loss at step 48800 is 7486.731119384765\n",
      "epoch 3 loss at step 49600 is 10836.018979492188\n",
      "epoch 3 loss at step 50400 is 6575.089641113282\n",
      "epoch 3 loss at step 51200 is 37560.1878100586\n",
      "epoch 3 loss at step 52000 is 4779.208041992188\n",
      "epoch 3 loss at step 52800 is 7907.491171875\n",
      "epoch 3 loss at step 53600 is 7634.221077880859\n",
      "epoch 3 loss at step 54400 is 10125.842309570313\n",
      "epoch 3 loss at step 55200 is 9326.258308105469\n",
      "epoch 3 loss at step 56000 is 9050.420842285157\n",
      "epoch 3 loss at step 56800 is 6300.666777954101\n",
      "epoch 3 loss at step 57600 is 4190.66177734375\n",
      "epoch 3 loss at step 58400 is 36481.4339477539\n",
      "epoch 3 loss at step 59200 is 6330.590185546875\n",
      "epoch 3 loss at step 60000 is 52729.88566223145\n",
      "epoch 3 loss at step 60800 is 20377.957097167968\n",
      "epoch 3 loss at step 61600 is 6316.4641015625\n",
      "epoch 3 loss at step 62400 is 9750.56724609375\n",
      "epoch 3 loss at step 63200 is 9071.759765625\n",
      "epoch 3 loss at step 63440 is 9646.766494140626\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "def train():\n",
    "    epochs = 4\n",
    "    total_loss = 0\n",
    "    log_step = 100\n",
    "    \n",
    "    print(f'Training on size: {len(train_dataset)}')\n",
    "    recommendation_model.train()\n",
    "    \n",
    "    for epoch_i in range(epochs):\n",
    "        step_count = 0\n",
    "        for i, train_data in enumerate(train_loader):\n",
    "            users = train_data[\"user_id\"].to(device)\n",
    "            items = train_data[\"title\"].to(device)\n",
    "    \n",
    "            output = recommendation_model(users, items)\n",
    "            output = output.squeeze()\n",
    "            \n",
    "            hours = train_data[\"hours\"].to(torch.float32).to(device)\n",
    "    \n",
    "            \n",
    "    \n",
    "            loss = loss_fn(output, hours)\n",
    "            total_loss += loss.sum().item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            step_count += len(train_data[\"user_id\"])\n",
    "    \n",
    "            if (step_count % log_step == 0 or i == len(train_loader) - 1):\n",
    "                avg_loss = (total_loss / log_step)\n",
    "                print(f\"epoch {epoch_i} loss at step {step_count} is {avg_loss}\")\n",
    "                losses.append(avg_loss)\n",
    "                total_loss = 0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 198.7710\n"
     ]
    }
   ],
   "source": [
    "  # Root Mean Squared Error\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "recommendation_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, valid_data in enumerate(valid_loader):\n",
    "        model_output = recommendation_model(valid_data['user_id'].to(device), valid_data['title'].to(device))\n",
    "\n",
    "        hours = valid_data['hours'].to(device)\n",
    "        y_true.extend(hours.cpu().numpy()) \n",
    "        y_pred.extend(model_output.cpu().numpy())\n",
    "\n",
    "\n",
    "# actually calc RMSE\n",
    "rmse = root_mean_squared_error(y_true, y_pred)\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision @ 50: 0.6815\n",
      "recall @ 50: 0.8595\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def calculate_precision_recall(user_hours, k, threshold):\n",
    "    user_hours.sort(key=lambda x: x[0], reverse=True)\n",
    "    n_rel = sum(true_r >= threshold for _, true_r in user_hours)\n",
    "    n_rec_k = sum(est >= threshold for est, _ in user_hours[:k])\n",
    "    n_rel_and_rec_k = sum(\n",
    "        (true_r >= threshold) and (est >= threshold) for est, true_r in user_hours[:k]\n",
    "    )\n",
    "\n",
    "    precision = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "    recall = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "user_hours_comparison = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for valid_data in valid_loader:\n",
    "        users = valid_data[\"user_id\"].to(device)\n",
    "        titles = valid_data[\"title\"].to(device)\n",
    "        hours = valid_data[\"hours\"].to(device)\n",
    "        output = recommendation_model(users, titles)\n",
    "\n",
    "        for user, pred, true in zip(users, output, hours):\n",
    "            user_hours_comparison[user.item()].append((pred[0].item(), true.item()))\n",
    "\n",
    "user_precisions = dict()\n",
    "user_based_recalls = dict()\n",
    "\n",
    "k = 50\n",
    "threshold = 3\n",
    "\n",
    "for user_id, user_hours in user_hours_comparison.items():\n",
    "    precision, recall = calculate_precision_recall(user_hours, k, threshold)\n",
    "    user_precisions[user_id] = precision\n",
    "    user_based_recalls[user_id] = recall\n",
    "\n",
    "\n",
    "    average_precision = sum(prec for prec in user_precisions.values()) / len(\n",
    "    user_precisions\n",
    ")\n",
    "average_recall = sum(rec for rec in user_based_recalls.values()) / len(\n",
    "    user_based_recalls\n",
    ")\n",
    "\n",
    "print(f\"precision @ {k}: {average_precision:.4f}\")\n",
    "print(f\"recall @ {k}: {average_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 1: ['Football Manager 2012' 'Football Manager 2014' 'Football Manager 2013'\n",
      " 'Football Manager 2015' 'Football Manager 2011']\n",
      "Recommendations for user 4: ['Football Manager 2012' 'Football Manager 2014' 'Football Manager 2013'\n",
      " 'Football Manager 2015' 'Counter-Strike Global Offensive']\n"
     ]
    }
   ],
   "source": [
    "def top_recommendations(user_id, all_titles, k=5, batch_size=100):\n",
    "    recommendation_model.eval()\n",
    "\n",
    "\n",
    "    \n",
    "    played_titles = set(df[df['user_id'] == user_id]['title'].tolist())\n",
    "    unplayed_titles = [m for m in all_titles if m not in played_titles]\n",
    "    # fill unwatched movies\n",
    "    # for m in all_movies:\n",
    "    #     if m not in watched_movies:\n",
    "    #         unwatched_movies.append(m)\n",
    "\n",
    "    prediction = []\n",
    "    top_k_recommendations = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(unplayed_titles), batch_size):\n",
    "            batched_unwatched = unplayed_titles[i:i+batch_size]\n",
    "            title_tensor = torch.tensor(batched_unwatched).to(device)\n",
    "            user_tensor = torch.tensor([user_id] * len(batched_unwatched)).to(device)\n",
    "            prediction_model = recommendation_model(user_tensor, title_tensor).view(-1).tolist()\n",
    "            prediction.extend(zip(batched_unwatched, prediction_model))\n",
    "\n",
    "    prediction.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for (m_id, _) in prediction[:k]:\n",
    "        top_k_recommendations.append(m_id)\n",
    "\n",
    "    # Convert this encoded movieId's back to their original ids\n",
    "    top_k_recommendations = lbl_item.inverse_transform(top_k_recommendations)\n",
    "    \n",
    "    return top_k_recommendations\n",
    "\n",
    "# ---------------\n",
    "\n",
    "all_games = df['title'].unique().tolist()\n",
    "user_id = 1\n",
    "\n",
    "recommendations = top_recommendations(user_id, all_games, k=5)\n",
    "print(f\"Recommendations for user {user_id}: {recommendations}\")\n",
    "\n",
    "# for i in recommendations:\n",
    "#     print(movies_dict[i])\n",
    "\n",
    "user_id = 4\n",
    "recommendations = top_recommendations(user_id, all_games, k=5)\n",
    "print(f\"Recommendations for user {user_id}: {recommendations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  title\n",
      "0     5088   3067\n",
      "2     5088   1162\n",
      "4     5088   2813\n",
      "6     5088   1163\n",
      "8     5088   1733\n"
     ]
    }
   ],
   "source": [
    "print(df[['user_id', 'title']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>action</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5088</td>\n",
       "      <td>3067</td>\n",
       "      <td>play</td>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5088</td>\n",
       "      <td>1162</td>\n",
       "      <td>play</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5088</td>\n",
       "      <td>2813</td>\n",
       "      <td>play</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5088</td>\n",
       "      <td>1163</td>\n",
       "      <td>play</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5088</td>\n",
       "      <td>1733</td>\n",
       "      <td>play</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199990</th>\n",
       "      <td>4056</td>\n",
       "      <td>1155</td>\n",
       "      <td>play</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199992</th>\n",
       "      <td>4056</td>\n",
       "      <td>1833</td>\n",
       "      <td>play</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199994</th>\n",
       "      <td>4056</td>\n",
       "      <td>3220</td>\n",
       "      <td>play</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>4056</td>\n",
       "      <td>1375</td>\n",
       "      <td>play</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>4056</td>\n",
       "      <td>2372</td>\n",
       "      <td>play</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70489 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  title action  hours\n",
       "0          5088   3067   play  273.0\n",
       "2          5088   1162   play   87.0\n",
       "4          5088   2813   play   14.9\n",
       "6          5088   1163   play   12.1\n",
       "8          5088   1733   play    8.9\n",
       "...         ...    ...    ...    ...\n",
       "199990     4056   1155   play    2.4\n",
       "199992     4056   1833   play    2.2\n",
       "199994     4056   3220   play    1.5\n",
       "199996     4056   1375   play    1.5\n",
       "199998     4056   2372   play    1.4\n",
       "\n",
       "[70489 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.nunique of 0         5088\n",
       "2         5088\n",
       "4         5088\n",
       "6         5088\n",
       "8         5088\n",
       "          ... \n",
       "199990    4056\n",
       "199992    4056\n",
       "199994    4056\n",
       "199996    4056\n",
       "199998    4056\n",
       "Name: user_id, Length: 70489, dtype: int64>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_id'].nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
